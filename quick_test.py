#!/usr/bin/env python3
"""
Quick Data Pipeline Test
"""

import json
import sqlite3
from pathlib import Path

# Setup paths
project_root = Path("/home/gyashu/projects/mini_search_engine")
raw_data_dir = project_root / "RawHTMLdata"
processed_dir = project_root / "ai_search" / "backend" / "data" / "processed"
processed_dir.mkdir(parents=True, exist_ok=True)
db_path = processed_dir / "documents.db"

print("ğŸ”§ MINI SEARCH ENGINE - QUICK PIPELINE TEST")
print("=" * 50)

# Check raw data
if not raw_data_dir.exists():
    print(f"âŒ Raw data directory not found: {raw_data_dir}")
    exit(1)

json_files = list(raw_data_dir.glob('*.json'))
print(f"ğŸ“Š Found {len(json_files)} JSON batch files")

if not json_files:
    print("âŒ No JSON files found")
    exit(1)

# Test first file
print(f"ğŸ§ª Testing first file: {json_files[0].name}")
try:
    with open(json_files[0], 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… JSON loaded successfully")
    print(f"ğŸ“„ Data type: {type(data)}")
    
    if isinstance(data, list):
        print(f"ğŸ“ Found {len(data)} items in array")
        if data:
            item = data[0]
            print(f"ğŸ”‘ First item keys: {list(item.keys())}")
            print(f"ğŸŒ Sample URL: {item.get('url', 'N/A')}")
            
            # Check content
            content = item.get('content', '')
            if content:
                print(f"ğŸ“„ Content length: {len(content)} chars")
                print(f"ğŸ“ Content preview: {content[:100]}...")
            else:
                print("âš ï¸  No 'content' field found")
                
except Exception as e:
    print(f"âŒ Error processing file: {e}")
    exit(1)

# Initialize database
print("\nğŸ—„ï¸  Initializing database...")
conn = sqlite3.connect(db_path)
cursor = conn.cursor()

cursor.execute('''
CREATE TABLE IF NOT EXISTS documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    url TEXT UNIQUE NOT NULL,
    title TEXT,
    content TEXT NOT NULL,
    domain TEXT NOT NULL,
    word_count INTEGER,
    content_hash TEXT UNIQUE,
    timestamp TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
''')

cursor.execute('''
CREATE INDEX IF NOT EXISTS idx_content_fts ON documents(content)
''')

cursor.execute('''
CREATE INDEX IF NOT EXISTS idx_domain ON documents(domain)
''')

conn.commit()
conn.close()

print(f"âœ… Database initialized at: {db_path}")
print(f"ğŸ¯ Ready to process {len(json_files)} files with your 6.3GB of data!")

print("\nğŸ“‹ CURRENT PROJECT STATUS:")
print("âœ… Raw crawler data: 6.3GB, 2,051 files")
print("âœ… Database schema: Created")
print("âœ… AI search backend: Available")
print("â³ Data processing: Ready to start")

print("\nğŸš€ To complete the search engine:")
print("1. Run the full pipeline (will take 10-30 minutes)")
print("2. Process all 2,051 batch files")
print("3. Create searchable database")
print("4. Test search functionality")
