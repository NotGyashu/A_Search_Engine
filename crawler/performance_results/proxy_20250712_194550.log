Starting proxy test...
ğŸš€ HYBRID SPEED CRAWLER - Production-Ready Ultimate Performance
================================================================
Configuration - Phase 2 Enhanced:
- Network workers: 8
- HTML processors: 4
- Max crawl depth: 3
- Max queue size: 10000
- Target performance: 300+ pages/sec
- Phase 2 features: Sharded disk, Work stealing, HTML pipeline
================================================================

ğŸ”§ Initializing proxy system for 200-500+ pages/sec performance...
ğŸ“‹ Added 4 proxy endpoints (premium proxy enabled)
ï¿½ Premium proxy 56.228.68.250:3128 is enabled for testing
ğŸ“‹ Loaded proxy configuration with 4 endpoints
ğŸ”§ Applying proxy configuration...
ProxyPool: Added proxy premium_proxy_1 (56.228.68.250:3128)
ğŸš€ Marked premium proxy as HEALTHY: premium_proxy_1
âœ… Health check confirmed: HEALTHY
âœ… Added proxy: premium_proxy_1 (56.228.68.250:3128)
â¸ï¸  Skipped disabled proxy: free_us_1
â¸ï¸  Skipped disabled proxy: free_eu_1
â¸ï¸  Skipped disabled proxy: socks5_proxy_1
ğŸ“Š Proxy configuration applied: 1/4 proxies active
ğŸ“Š Final proxy stats: 0 healthy, 0 total
âœ… Proxy system initialized but INACTIVE (no healthy proxies)
âš ï¸  No healthy proxies available - using direct connections only
ğŸ’¡ To enable proxies:
   1. Edit config/proxy_config.json
   2. Add working proxy endpoints
   3. Set enabled: true for proxy endpoints
- Total proxies: 0
- Healthy proxies: 0
- Domain sharding: ENABLED
- Target performance: 50 req/sec per proxy
================================================================

âœ… Seeded hybrid crawler with 33/33 URLs
ğŸ“Š POST-SEED QUEUE STATUS:
   Memory Queue: 33 URLs
   Sharded Disk Queue: 505834 URLs
   Work Stealing Queue: 0 URLs
   HTML Processing Queue: 0 tasks
ğŸš€ Starting Phase 2 workers:
   Network workers: 8
   HTML processors: 4
ğŸ”§ HTML processor 0 starting...
ğŸ”§ HTML processor 1 starting...
ğŸ”§ HTML processor 2 starting...
ğŸ”§ HTML processor 3 starting...
ğŸƒ Worker 6 starting with MAX_CONCURRENT=30
ğŸƒ Worker 3 starting with MAX_CONCURRENT=30
ğŸƒ Worker 5 starting with MAX_CONCURRENT=30
ğŸ”„ Worker 5 skipping domain en.wikipedia.org (consecutive limit)
ğŸƒ Worker 2 starting with MAX_CONCURRENT=30
ğŸƒ Worker 1 starting with MAX_CONCURRENT=30
ğŸƒ Worker 4 starting with MAX_CONCURRENT=30
ğŸƒ Worker 7 starting with MAX_CONCURRENT=30
ğŸƒ Worker 0 starting with MAX_CONCURRENT=30
ğŸ”„ Worker 7 skipping domain info.arxiv.org (consecutive limit)
ğŸ“Š POST-WORKER START STATUS (after 2s):
   Memory Queue: 1470 URLs
   Sharded Disk Queue: 501610 URLs
   Work Stealing Queue: 2084 URLs
   HTML Processing Queue: 0 tasks

ğŸš€ Phase 2 Enhanced Crawler started!
   Network pipeline: 8 workers
   HTML pipeline: 4 processors
   Target: 300+ pages/sec with pipelined processing
Press Ctrl+C to gracefully shutdown

ğŸ“Š Starting continuous queue & speed monitoring...
ğŸ” STARTUP QUEUE STATUS:
   Memory Queue: 1470 URLs
   Sharded Disk Queue: 501610 URLs
   Work Stealing Queue: 2084 URLs
   HTML Processing Queue: 0 tasks
   Total Available: 505164 URLs

ğŸ”§ HTML processor 0: 1 batches, 34 links (17.0 links/s)
ğŸ”§ HTML processor 1: 1 batches, 50 links (25.0 links/s)
ğŸ”§ HTML processor 2: 1 batches, 50 links (25.0 links/s)
ğŸ”§ HTML processor 0: 2 batches, 84 links (42.0 links/s)
ğŸ”§ HTML processor 3: 1 batches, 46 links (23.0 links/s)
ğŸ”§ HTML processor 1: 2 batches, 89 links (44.5 links/s)
ğŸ”§ HTML processor 0: 3 batches, 123 links (61.5 links/s)
ğŸ”§ HTML processor 2: 2 batches, 100 links (50.0 links/s)
ğŸ”§ HTML processor 3: 2 batches, 96 links (32.0 links/s)
ğŸ”§ HTML processor 1: 3 batches, 139 links (46.3 links/s)
ğŸ”§ HTML processor 1: 4 batches, 194 links (64.7 links/s)
ğŸ”§ HTML processor 2: 3 batches, 150 links (50.0 links/s)
ğŸ”§ HTML processor 3: 3 batches, 128 links (42.7 links/s)
ğŸ”„ Worker 7 skipping domain arxiv.org (consecutive limit)
ğŸ”§ HTML processor 0: 4 batches, 138 links (46.0 links/s)
ğŸ”§ HTML processor 3: 4 batches, 178 links (59.3 links/s)
ğŸ”§ HTML processor 2: 4 batches, 200 links (66.7 links/s)
ğŸ”„ Worker 4 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 3 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
ğŸ”„ MONITORING STATUS: Time=5s | Queue=âœ…2726 | DiskQueue=501770 | WorkStealing=4809 | HTMLQueue=0 | Rate=14.4 pages/sec | TotalProcessed=101 | ProxyActive=NO
ğŸ”„ Worker 6 skipping domain arxiv.org (consecutive limit)
Worker 2 blacklisted domain: httpbin.org
ğŸ”„ Worker 2 skipping domain ace.wikipedia.org (consecutive limit)
ğŸ” Worker 2 diagnostics: Queue=3151 | Dequeued=97 | Active=28 | Processed=5 | Skipped: BL=1 R=0 RL=48
ğŸ” Worker 6 diagnostics: Queue=3160 | Dequeued=386 | Active=24 | Processed=124 | Skipped: BL=0 R=0 RL=101
ğŸ” Worker 5 diagnostics: Queue=3522 | Dequeued=110 | Active=27 | Processed=12 | Skipped: BL=0 R=0 RL=55
ğŸ” Worker 1 diagnostics: Queue=3570 | Dequeued=147 | Active=26 | Processed=9 | Skipped: BL=0 R=0 RL=96
ğŸ”„ Worker 1 skipping domain arxiv.org (consecutive limit)
ğŸ”„ MONITORING STATUS: Time=10s | Queue=âœ…3981 | DiskQueue=506119 | WorkStealing=4930 | HTMLQueue=0 | Rate=20.4 pages/sec | TotalProcessed=245 | ProxyActive=NO
Worker 2 blacklisted domain: ba.wikipedia.org
ğŸ”„ Worker 2 skipping domain arxiv.org (consecutive limit)
ğŸ” Worker 3 diagnostics: Queue=5079 | Dequeued=96 | Active=11 | Processed=7 | Skipped: BL=0 R=0 RL=57
ğŸ”„ Worker 3 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 3 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 3 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 3 skipping domain arxiv.org (consecutive limit)
ğŸ”„ Worker 3 skipping domain arxiv.org (consecutive limit)
ğŸ” Worker 4 diagnostics: Queue=5100 | Dequeued=132 | Active=26 | Processed=4 | Skipped: BL=0 R=0 RL=82
ğŸ” Worker 0 diagnostics: Queue=5085 | Dequeued=50 | Active=5 | Processed=2 | Skipped: BL=0 R=0 RL=16
ğŸ”„ Worker 0 skipping domain arxiv.org (consecutive limit)
ğŸ” Worker 7 diagnostics: Queue=5044 | Dequeued=132 | Active=1 | Processed=8 | Skipped: BL=0 R=0 RL=90
ğŸ”„ MONITORING STATUS: Time=15s | Queue=âœ…5072 | DiskQueue=511716 | WorkStealing=4930 | HTMLQueue=0 | Rate=24.5 pages/sec | TotalProcessed=416 | ProxyActive=NO
Worker 3 blacklisted domain: stackoverflow.com
ğŸ”„ Worker 4 skipping domain ace.wikipedia.org (consecutive limit)
ğŸ” Worker 2 diagnostics: Queue=5457 | Dequeued=169 | Active=9 | Processed=33 | Skipped: BL=3 R=0 RL=66
ğŸ”„ Worker 2 skipping domain global.cornell.edu (consecutive limit)
ğŸ” Worker 6 diagnostics: Queue=5493 | Dequeued=549 | Active=23 | Processed=238 | Skipped: BL=3 R=0 RL=142
ğŸ” Worker 1 diagnostics: Queue=5582 | Dequeued=249 | Active=22 | Processed=96 | Skipped: BL=2 R=0 RL=115
ğŸ” Worker 5 diagnostics: Queue=5608 | Dequeued=227 | Active=23 | Processed=120 | Skipped: BL=1 R=0 RL=77
ğŸ”„ Worker 5 skipping domain alt.wikipedia.org (consecutive limit)
ğŸ”„ MONITORING STATUS: Time=20s | Queue=âœ…5861 | DiskQueue=515689 | WorkStealing=4930 | HTMLQueue=11 | Rate=26.3 pages/sec | TotalProcessed=579 | ProxyActive=NO
ğŸ”§ PRE-FILTER: Blocked 3000 low-quality URLs
Worker 3 blacklisted domain: am.wiktionary.org
Worker 7 blacklisted domain: awa.wikipedia.org
ğŸ”„ Worker 7 skipping domain privacy.cornell.edu (consecutive limit)
Worker 2 blacklisted domain: www.wikidata.org
Worker 4 blacklisted domain: awa.wikipedia.org
ğŸ” Worker 4 diagnostics: Queue=6832 | Dequeued=214 | Active=20 | Processed=19 | Skipped: BL=10 R=0 RL=110
ğŸ” Worker 3 diagnostics: Queue=6905 | Dequeued=225 | Active=25 | Processed=28 | Skipped: BL=1 R=0 RL=79
ğŸ” Worker 7 diagnostics: Queue=6988 | Dequeued=231 | Active=30 | Processed=20 | Skipped: BL=8 R=0 RL=129
ğŸ” Worker 0 diagnostics: Queue=7005 | Dequeued=177 | Active=26 | Processed=23 | Skipped: BL=26 R=0 RL=42
ğŸ”„ MONITORING STATUS: Time=25s | Queue=âœ…7031 | DiskQueue=519762 | WorkStealing=4930 | HTMLQueue=3 | Rate=28.0 pages/sec | TotalProcessed=756 | ProxyActive=NO
ğŸ”„ Worker 4 skipping domain zu.wikipedia.org (consecutive limit)
ğŸ”„ Worker 5 skipping domain hy.wikipedia.org (consecutive limit)
ğŸ”„ Worker 0 skipping domain hy.wikipedia.org (consecutive limit)
ğŸ” Worker 1 diagnostics: Queue=7456 | Dequeued=362 | Active=30 | Processed=180 | Skipped: BL=11 R=0 RL=140
ğŸ” Worker 5 diagnostics: Queue=7451 | Dequeued=340 | Active=19 | Processed=197 | Skipped: BL=11 R=0 RL=103
ğŸ”„ Worker 5 skipping domain en.wikinews.org (consecutive limit)
ğŸ” Worker 6 diagnostics: Queue=7460 | Dequeued=686 | Active=29 | Processed=318 | Skipped: BL=32 R=0 RL=168
ğŸ” Worker 2 diagnostics: Queue=7428 | Dequeued=290 | Active=28 | Processed=77 | Skipped: BL=15 R=0 RL=112
ğŸ”„ MONITORING STATUS: Time=30s | Queue=âœ…7445 | DiskQueue=525151 | WorkStealing=4930 | HTMLQueue=0 | Rate=29.6 pages/sec | TotalProcessed=947 | ProxyActive=NO
ğŸ”„ Worker 3 skipping domain hy.m.wikipedia.org (consecutive limit)
ğŸ”„ Worker 7 skipping domain hy.m.wikipedia.org (consecutive limit)
Worker 1 blacklisted domain: awa.wikipedia.org
