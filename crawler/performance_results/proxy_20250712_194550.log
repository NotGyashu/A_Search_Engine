Starting proxy test...
🚀 HYBRID SPEED CRAWLER - Production-Ready Ultimate Performance
================================================================
Configuration - Phase 2 Enhanced:
- Network workers: 8
- HTML processors: 4
- Max crawl depth: 3
- Max queue size: 10000
- Target performance: 300+ pages/sec
- Phase 2 features: Sharded disk, Work stealing, HTML pipeline
================================================================

🔧 Initializing proxy system for 200-500+ pages/sec performance...
📋 Added 4 proxy endpoints (premium proxy enabled)
� Premium proxy 56.228.68.250:3128 is enabled for testing
📋 Loaded proxy configuration with 4 endpoints
🔧 Applying proxy configuration...
ProxyPool: Added proxy premium_proxy_1 (56.228.68.250:3128)
🚀 Marked premium proxy as HEALTHY: premium_proxy_1
✅ Health check confirmed: HEALTHY
✅ Added proxy: premium_proxy_1 (56.228.68.250:3128)
⏸️  Skipped disabled proxy: free_us_1
⏸️  Skipped disabled proxy: free_eu_1
⏸️  Skipped disabled proxy: socks5_proxy_1
📊 Proxy configuration applied: 1/4 proxies active
📊 Final proxy stats: 0 healthy, 0 total
✅ Proxy system initialized but INACTIVE (no healthy proxies)
⚠️  No healthy proxies available - using direct connections only
💡 To enable proxies:
   1. Edit config/proxy_config.json
   2. Add working proxy endpoints
   3. Set enabled: true for proxy endpoints
- Total proxies: 0
- Healthy proxies: 0
- Domain sharding: ENABLED
- Target performance: 50 req/sec per proxy
================================================================

✅ Seeded hybrid crawler with 33/33 URLs
📊 POST-SEED QUEUE STATUS:
   Memory Queue: 33 URLs
   Sharded Disk Queue: 505834 URLs
   Work Stealing Queue: 0 URLs
   HTML Processing Queue: 0 tasks
🚀 Starting Phase 2 workers:
   Network workers: 8
   HTML processors: 4
🔧 HTML processor 0 starting...
🔧 HTML processor 1 starting...
🔧 HTML processor 2 starting...
🔧 HTML processor 3 starting...
🏃 Worker 6 starting with MAX_CONCURRENT=30
🏃 Worker 3 starting with MAX_CONCURRENT=30
🏃 Worker 5 starting with MAX_CONCURRENT=30
🔄 Worker 5 skipping domain en.wikipedia.org (consecutive limit)
🏃 Worker 2 starting with MAX_CONCURRENT=30
🏃 Worker 1 starting with MAX_CONCURRENT=30
🏃 Worker 4 starting with MAX_CONCURRENT=30
🏃 Worker 7 starting with MAX_CONCURRENT=30
🏃 Worker 0 starting with MAX_CONCURRENT=30
🔄 Worker 7 skipping domain info.arxiv.org (consecutive limit)
📊 POST-WORKER START STATUS (after 2s):
   Memory Queue: 1470 URLs
   Sharded Disk Queue: 501610 URLs
   Work Stealing Queue: 2084 URLs
   HTML Processing Queue: 0 tasks

🚀 Phase 2 Enhanced Crawler started!
   Network pipeline: 8 workers
   HTML pipeline: 4 processors
   Target: 300+ pages/sec with pipelined processing
Press Ctrl+C to gracefully shutdown

📊 Starting continuous queue & speed monitoring...
🔍 STARTUP QUEUE STATUS:
   Memory Queue: 1470 URLs
   Sharded Disk Queue: 501610 URLs
   Work Stealing Queue: 2084 URLs
   HTML Processing Queue: 0 tasks
   Total Available: 505164 URLs

🔧 HTML processor 0: 1 batches, 34 links (17.0 links/s)
🔧 HTML processor 1: 1 batches, 50 links (25.0 links/s)
🔧 HTML processor 2: 1 batches, 50 links (25.0 links/s)
🔧 HTML processor 0: 2 batches, 84 links (42.0 links/s)
🔧 HTML processor 3: 1 batches, 46 links (23.0 links/s)
🔧 HTML processor 1: 2 batches, 89 links (44.5 links/s)
🔧 HTML processor 0: 3 batches, 123 links (61.5 links/s)
🔧 HTML processor 2: 2 batches, 100 links (50.0 links/s)
🔧 HTML processor 3: 2 batches, 96 links (32.0 links/s)
🔧 HTML processor 1: 3 batches, 139 links (46.3 links/s)
🔧 HTML processor 1: 4 batches, 194 links (64.7 links/s)
🔧 HTML processor 2: 3 batches, 150 links (50.0 links/s)
🔧 HTML processor 3: 3 batches, 128 links (42.7 links/s)
🔄 Worker 7 skipping domain arxiv.org (consecutive limit)
🔧 HTML processor 0: 4 batches, 138 links (46.0 links/s)
🔧 HTML processor 3: 4 batches, 178 links (59.3 links/s)
🔧 HTML processor 2: 4 batches, 200 links (66.7 links/s)
🔄 Worker 4 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 3 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
🔄 MONITORING STATUS: Time=5s | Queue=✅2726 | DiskQueue=501770 | WorkStealing=4809 | HTMLQueue=0 | Rate=14.4 pages/sec | TotalProcessed=101 | ProxyActive=NO
🔄 Worker 6 skipping domain arxiv.org (consecutive limit)
Worker 2 blacklisted domain: httpbin.org
🔄 Worker 2 skipping domain ace.wikipedia.org (consecutive limit)
🔍 Worker 2 diagnostics: Queue=3151 | Dequeued=97 | Active=28 | Processed=5 | Skipped: BL=1 R=0 RL=48
🔍 Worker 6 diagnostics: Queue=3160 | Dequeued=386 | Active=24 | Processed=124 | Skipped: BL=0 R=0 RL=101
🔍 Worker 5 diagnostics: Queue=3522 | Dequeued=110 | Active=27 | Processed=12 | Skipped: BL=0 R=0 RL=55
🔍 Worker 1 diagnostics: Queue=3570 | Dequeued=147 | Active=26 | Processed=9 | Skipped: BL=0 R=0 RL=96
🔄 Worker 1 skipping domain arxiv.org (consecutive limit)
🔄 MONITORING STATUS: Time=10s | Queue=✅3981 | DiskQueue=506119 | WorkStealing=4930 | HTMLQueue=0 | Rate=20.4 pages/sec | TotalProcessed=245 | ProxyActive=NO
Worker 2 blacklisted domain: ba.wikipedia.org
🔄 Worker 2 skipping domain arxiv.org (consecutive limit)
🔍 Worker 3 diagnostics: Queue=5079 | Dequeued=96 | Active=11 | Processed=7 | Skipped: BL=0 R=0 RL=57
🔄 Worker 3 skipping domain arxiv.org (consecutive limit)
🔄 Worker 3 skipping domain arxiv.org (consecutive limit)
🔄 Worker 3 skipping domain arxiv.org (consecutive limit)
🔄 Worker 3 skipping domain arxiv.org (consecutive limit)
🔄 Worker 3 skipping domain arxiv.org (consecutive limit)
🔍 Worker 4 diagnostics: Queue=5100 | Dequeued=132 | Active=26 | Processed=4 | Skipped: BL=0 R=0 RL=82
🔍 Worker 0 diagnostics: Queue=5085 | Dequeued=50 | Active=5 | Processed=2 | Skipped: BL=0 R=0 RL=16
🔄 Worker 0 skipping domain arxiv.org (consecutive limit)
🔍 Worker 7 diagnostics: Queue=5044 | Dequeued=132 | Active=1 | Processed=8 | Skipped: BL=0 R=0 RL=90
🔄 MONITORING STATUS: Time=15s | Queue=✅5072 | DiskQueue=511716 | WorkStealing=4930 | HTMLQueue=0 | Rate=24.5 pages/sec | TotalProcessed=416 | ProxyActive=NO
Worker 3 blacklisted domain: stackoverflow.com
🔄 Worker 4 skipping domain ace.wikipedia.org (consecutive limit)
🔍 Worker 2 diagnostics: Queue=5457 | Dequeued=169 | Active=9 | Processed=33 | Skipped: BL=3 R=0 RL=66
🔄 Worker 2 skipping domain global.cornell.edu (consecutive limit)
🔍 Worker 6 diagnostics: Queue=5493 | Dequeued=549 | Active=23 | Processed=238 | Skipped: BL=3 R=0 RL=142
🔍 Worker 1 diagnostics: Queue=5582 | Dequeued=249 | Active=22 | Processed=96 | Skipped: BL=2 R=0 RL=115
🔍 Worker 5 diagnostics: Queue=5608 | Dequeued=227 | Active=23 | Processed=120 | Skipped: BL=1 R=0 RL=77
🔄 Worker 5 skipping domain alt.wikipedia.org (consecutive limit)
🔄 MONITORING STATUS: Time=20s | Queue=✅5861 | DiskQueue=515689 | WorkStealing=4930 | HTMLQueue=11 | Rate=26.3 pages/sec | TotalProcessed=579 | ProxyActive=NO
🔧 PRE-FILTER: Blocked 3000 low-quality URLs
Worker 3 blacklisted domain: am.wiktionary.org
Worker 7 blacklisted domain: awa.wikipedia.org
🔄 Worker 7 skipping domain privacy.cornell.edu (consecutive limit)
Worker 2 blacklisted domain: www.wikidata.org
Worker 4 blacklisted domain: awa.wikipedia.org
🔍 Worker 4 diagnostics: Queue=6832 | Dequeued=214 | Active=20 | Processed=19 | Skipped: BL=10 R=0 RL=110
🔍 Worker 3 diagnostics: Queue=6905 | Dequeued=225 | Active=25 | Processed=28 | Skipped: BL=1 R=0 RL=79
🔍 Worker 7 diagnostics: Queue=6988 | Dequeued=231 | Active=30 | Processed=20 | Skipped: BL=8 R=0 RL=129
🔍 Worker 0 diagnostics: Queue=7005 | Dequeued=177 | Active=26 | Processed=23 | Skipped: BL=26 R=0 RL=42
🔄 MONITORING STATUS: Time=25s | Queue=✅7031 | DiskQueue=519762 | WorkStealing=4930 | HTMLQueue=3 | Rate=28.0 pages/sec | TotalProcessed=756 | ProxyActive=NO
🔄 Worker 4 skipping domain zu.wikipedia.org (consecutive limit)
🔄 Worker 5 skipping domain hy.wikipedia.org (consecutive limit)
🔄 Worker 0 skipping domain hy.wikipedia.org (consecutive limit)
🔍 Worker 1 diagnostics: Queue=7456 | Dequeued=362 | Active=30 | Processed=180 | Skipped: BL=11 R=0 RL=140
🔍 Worker 5 diagnostics: Queue=7451 | Dequeued=340 | Active=19 | Processed=197 | Skipped: BL=11 R=0 RL=103
🔄 Worker 5 skipping domain en.wikinews.org (consecutive limit)
🔍 Worker 6 diagnostics: Queue=7460 | Dequeued=686 | Active=29 | Processed=318 | Skipped: BL=32 R=0 RL=168
🔍 Worker 2 diagnostics: Queue=7428 | Dequeued=290 | Active=28 | Processed=77 | Skipped: BL=15 R=0 RL=112
🔄 MONITORING STATUS: Time=30s | Queue=✅7445 | DiskQueue=525151 | WorkStealing=4930 | HTMLQueue=0 | Rate=29.6 pages/sec | TotalProcessed=947 | ProxyActive=NO
🔄 Worker 3 skipping domain hy.m.wikipedia.org (consecutive limit)
🔄 Worker 7 skipping domain hy.m.wikipedia.org (consecutive limit)
Worker 1 blacklisted domain: awa.wikipedia.org
